<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8"/>
    <meta content="notranslate" name="google"/>
    <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" name="viewport"/>
    <title>
      Linear Regression More Inference
    </title>
    <link href="lib\favicon.png" rel="icon" type="image/x-icon"/>
    <link href="./src/css/reset.css" rel="stylesheet"/>
    <link href="./src/css/reveal.css" rel="stylesheet"/>
    <link href="./src/css/revealpack.css" rel="stylesheet"/>
    <link href="./src/theme/drG.css" id="theme" rel="stylesheet"/>
    <!-- highlight.js theme -->
    <link href="./src/theme/vs.css" id="highlight-theme" rel="stylesheet"/>
    <!-- Custom CSS -->
    <!-- Custom Scripts -->
    <!-- Print PDF script -->
    <script>
      var link = document.createElement('link');
link.rel = 'stylesheet';
link.type = 'text/css';
link.href = window.location.search.match(/print-pdf/gi) ? './src/css/print/pdf.css' : './src/css/print/paper.css';
document.getElementsByTagName('head')[0].appendChild(link);
    </script>
    <!-- Deck CSS Injections -->
    <!-- Deck Script Injections -->
    <!-- Deck Raw Injections -->
  </head>
  <body>
    <div class="reveal">
      <div class="slides">
        <section data-background-image="lib/img/correlated-signals_bg.png" id="deck-title-slide">
          <div class="title-slide background">
            <div class="headline">
              <h2 class="r-fit-text">
                Linear Regression
              </h2>
              <h3>
                More Inference
              </h3>
            </div>
            <div class="sub-header">
              <p class="by">
                Khris Griffis, Ph.D.
              </p>
            </div>
            <div class="byline">
              <p class="byinfo">
                Lecture 15
              </p>
              <p class="byinfo">
                CSULA: ME3040
              </p>
            </div>
          </div>
        </section>
        <section>
          <div class="grid-wrapper">

<div class="header">

<h2>Today's Objectives</h2>

</div>

<div class="content">

<div

class="grid-generic full-width left-justify big"

style="grid-template-columns: 1fr; grid-auto-rows: auto; row-gap: 5vmin"

>

<div class="border-bottom fragment" data-fragment-index="1">

<p><i class="target"></i> Regression coefficients recap</p>

</div>

<div class="border-bottom fragment" data-fragment-index="2">

<p><i class="target"></i> Inferences For Linear Regression</p>

</div>

<div class="border-bottom fragment" data-fragment-index="3">

<p><i class="target"></i> Multiple Explanatory Variables</p>

</div>

</div>

</div>

</div>

<aside class="notes">

<p></p>

</aside>

<!-- </section> -->
        </section>
        <section data-background-image="lib/img/inferences_bg_3.png" id="section-title-1">
          <div class="grid-wrapper">
            <div class="section-title-content" id="section-content-1">
              <div class="section-number">
                <span class="large-number">
                  1
                </span>
              </div>
              <div class="headlines">
                <h2 class="r-fit-text">
                  Last Time...
                </h2>
                <h3>
                  Recap Of Linear Regression
                </h3>
              </div>
            </div>
          </div>
          <style>

#section-content-1.section-title-content {

background-color: rgba(240, 240, 240, 0.6) !important;

border-radius: 2rem !important;

box-shadow: 0 0 2rem 2rem rgba(240, 240, 240, 0.6) !important;

}

</style>

<aside class="notes">

<p>Let's look back at the derivation for the regression coefficients</p>

</aside>

</section> <!-- End section title -->

<!-- Setup -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2>Determining Coefficients</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr;grid-template-rows:1fr;gap:5px;">

<div style="font-size:80%;">

<p>

Given the system: \(\mathrm {X} {\boldsymbol {\beta }}=\mathbf {y} ,\) where



\[{\displaystyle \mathrm {X} ={\begin{bmatrix}X_{11}&X_{12}&\cdots &X_{1p}\\X_{21}&X_{22}&\cdots &X_{2p}\\\vdots &\vdots &\ddots &\vdots \\X_{n1}&X_{n2}&\cdots &X_{np}\end{bmatrix}},\qquad {\boldsymbol {\beta }}={\begin{bmatrix}\beta _{1}\\\beta _{2}\\\vdots \\\beta _{p}\end{bmatrix}},\qquad \mathbf {y} ={\begin{bmatrix}y_{1}\\y_{2}\\\vdots \\y_{n}\end{bmatrix}}.}\]

</p>

<p>

The estimated solution is: \({\displaystyle {\hat {\boldsymbol {\beta }}}=(\mathbf {X} ^{\mathsf {T}}\mathbf {X} )^{-1}\mathbf {X} ^{\mathsf {T}}\mathbf {y} .}\)

</p>

</div>

</div>

</div>

</div>

<aside class="notes">

<p>These are estimates!</p>

</aside>

</section>

<!-- Setup 2 -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2>Determining Coefficients</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr 1fr;grid-template-rows:1fr;gap:5px;font-size:90%;">

<div style="text-align:left;">

<p>

Consider the model: $\begin{align}

Y = \beta_0+\beta_1 X +\epsilon,

\end{align}$

</p>

<p>

where $\epsilon$ is a $\mathcal{N}(0,\sigma^2)$ random variable independent of $X$.

We can determine the $\beta$ coefficients by first taking the <span class="em">Expected Value</span>

from both sides and rearranging the equation:

$$\begin{align} %

\mathbb{E}Y &= \beta_0+\beta_1 \mathbb{E}X +\mathbb{E}[\epsilon]\\

&=\beta_0+\beta_1 \mathbb{E}X\\

\beta_0&=EY-\beta_1 EX.

\end{align}$$

</p>

</div>

<div style="text-align:left;">

<p>

For $\beta_1$, we turn to $\textrm{Cov}(X,Y)$ where

</p>

<p>

$\begin{align}

\textrm{Cov}(X,Y) &= \textrm{Cov}(X,\beta_0+\beta_1 X +\epsilon)\\

&=\beta_0 \textrm{Cov}(X,1)+\beta_1\textrm{Cov}(X,X)+\textrm{Cov}(X, \epsilon)\\

&=0+\beta_1 \textrm{Cov}(X,X)+0 \quad (\textrm{since $X$ and $\epsilon$ are independent})\\

&=\beta_1 \textrm{Var}(X)\\

\therefore\beta_1&=\frac{\textrm{Cov}(X,Y)}{\textrm{Var}(X)}

\end{align}$

</p>

<p class="framed border-success">

$$\begin{align}

&\hat{\beta_1}=\frac{s_{xy}}{s_{xx}},\\

&\hat{\beta_0}=\overline{y}-\hat{\beta_1} \overline{x}.

\end{align}$$

</p>

</div>

</div>

</div>

</div>

<aside class="notes">

<p>These are estimates!</p>

</aside>

</section>



<section>

<div class="grid-wrapper">

<div class="header">

<h2>Derivation of Coefficients</h2>

</div>

<div class="content">

<div class="grid-generic no-hang" style="grid-template-columns: repeat(2, 1fr); grid-auto-rows: auto; gap: 1vmin;">

<div class="no-hang pad-bottom fragment" data-fragment-index="1">

<p><i class="info huge" role="emoji" data-emoji="&#x2776;"></i></p>

<p class="small">The error in the ith observation is:</p>

<div class="smaller">$$\epsilon_i = y_i - \hat{y_i} = y_i - (\hat{\beta}_0 + \hat{\beta}_1x_i) $$</div>

<p class="smaller">(Observed - Predicted)</p>

</div>

<div class="no-hang pad-bottom fragment" data-fragment-index="3">

<p><i class="info huge" role="emoji" data-emoji="&#x2778;"></i></p>

<p class="small">Setting mean error to zero, we obtain:</p>

<div class="smaller">$$ \hat{\beta}_0 = \bar{y} - \hat{\beta}_1\bar{x} $$</div>

</div>

<div class="no-hang pad-bottom fragment" data-fragment-index="2">

<p><i class="info huge" role="emoji" data-emoji="&#x2777;"></i></p>

<p class="small">For a sample of n observations, the mean error is:</p>

<div class="smallest">$$ME = \bar{\epsilon} = \frac{1}{n} \sum \epsilon_i = \frac{1}{n} \sum \left[ y_i - (\hat{\beta}_0 + \hat{\beta}_1x_i) \right]$$</div>

<div class="smaller">$$ = \bar{y} - \hat{\beta}_0 - \hat{\beta}_1\bar{x} $$</div>

</div>

<div class="no-hang pad-bottom fragment" data-fragment-index="4">

<p><i class="info huge" role="emoji" data-emoji="&#x2779;"></i></p>

<p class="small">Substituting $\hat{\beta}_0$ in the error expression, we get:</p>

<div class="smaller">$$ \epsilon_i = y_i - \bar{y} + \hat{\beta}_1(\bar{x} - x_i) $$</div>

<p class="smallest">(Error term for each observation after substituting $\beta_0$)</p>

</div>

<div class="small framed border-success full-width fragment" style="grid-column:1/3;" data-fragment-index="5">

<p>

The derivation begins by defining the <span class="em">error for each data point</span>

and setting the average error to zero,

which leads to an expression for the intercept, \(\hat{\beta}_0\),

in terms of the mean values of \(y\) and \(x\) and the

slope, \(\hat{\beta}_1\).

</p>

</div>

</div>

</div>

</div>

<aside class="notes">

<p>

Note: This step assumes that the mean of the residuals (errors) is zero,

which is a property of the least squares regression.

</p>

</aside>

</section>



<!-- Slide 2: Continuation of Derivation of Regression Parameters -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2>Derivation of Coefficients</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns: repeat(2, 1fr); grid-auto-rows:auto; gap: 1vmin;">

<div class="no-hang">

<p class="small">The sum of squared errors SSE is:</p>

<div class="small">$$ SSE = \sum_{i=1}^{n} \epsilon_i^2 $$</div>

<div class="small">$$ = \sum_{i=1}^{n} \left[ (y_i - \bar{y}) + \hat{\beta}_1(x_i - \bar{x}) \right]^2 $$</div>

<div class="small">$$ = \sum_{i=1}^{n} \left[ (y_i - \bar{y})^2 + 2\hat{\beta}_1(y_i - \bar{y})(x_i - \bar{x}) + \hat{\beta}_1^2(x_i - \bar{x})^2 \right] $$</div>

<p class="smallest">Here, \(SSE\) represents the variability in the response variable that is not explained by the linear model.</p>

</div>

<div class="no-hang" data-fragment-index="1">

<p class="small">Differentiating this equation with respect to \(\hat{\beta}_1\), and equating the result to zero:</p>

<div class="small">$$ \frac{d(SSE)}{d\hat{\beta}_1} = -2s_{xy} + 2\hat{\beta}_1s_{x}^2 = 0 $$</div>

<p class="small">That is,</p>

<div class="small">$$ \hat{\beta}_1 = \frac{s_{xy}}{s_{x}^2} = \frac{\sum xy - n\bar{x}\bar{y}}{\sum x^2 - n(\bar{x})^2} $$</div>

</div>

<div class="framed border-info" style="grid-column:1/3;" data-fragment-index="2">

<p>

The slope \( \hat{\beta}_1 \) is derived by minimizing the sum of

squared errors (SSE) with respect to \( \hat{\beta}_1 \), leading

to the least squares estimates for the regression coefficients.

</p>

</div>

</div>

</div>

</div>

<aside class="notes">

<p>

\( s_{xy} \) and \( s_{x}^2 \) represent the covariance of \(x\) and \(y\), and the variance of \(x\) respectively, and are used to solve for the slope \( \hat{\beta}_1 \).

</p>

</aside>

</section>



<!-- Slide 3: Allocation of Variation -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2>Allocation of Variation</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns: 1fr 1fr; gap: 1vmin;">

<!-- Error Variance Without Regression -->

<div class="no-hang">

<p class="small">Error variance without Regression:</p>

<div class="smaller">$$ \text{Error} = e_i = y_i - \bar{y} $$</div>

<p class="small">Variance of Errors without regression:</p>

<div class="smallest">$$ \frac{1}{n - 1} \sum_{i=1}^{n} e_i^2 $$</div>

<div class="smallest">$$ = \frac{1}{n - 1} \sum_{i=1}^{n} (y_i - \bar{y})^2 $$</div>

<div class="smallest">$$ = \text{Variance of } y $$</div>

</div>

<!-- Total Sum of Squares (SST) -->

<div class="no-hang">

<p class="small">Total sum of squares (SST):</p>

<div class="smallest">$$ SST = \sum_{i=1}^{n} (y_i - \bar{y})^2 $$</div>

<div class="smallest">$$ = \left( \sum_{i=1}^{n} y_i^2 \right) - n\bar{y}^2 $$</div>

<div class="smallest">$$ = SSY - SSO $$</div>

<p class="smallest">Where \( SSY \) is the sum of squares of \( y \) and \( SSO \) is the sum of squares of \( \bar{y} \) equal to \( n\bar{y}^2 \).</p>

</div>

<!-- Sum of Squares due to Regression (SSR) -->

<div class="no-hang framed border-success fragment grid-generic" style="grid-column: 1/3;grid-template-columns: 1fr 1fr; gap: 1vmin;">

<p class="small">Sum of Squares due to Regression (SSR):</p>

<p class="small">Coefficient of Determination (\(R^2\)):</p>

<div class="smallest">$$ SSR = SST - SSE  = \sum(\hat{y}_i - \bar{y})^2$$</div>

<div class="smallest">$$ R^2 = \frac{SSR}{SST} = 1 - \frac{SSE}{SST} $$</div>

</div>

</div>

</div>

</div>

<aside class="notes">

<p>

SSR measures the amount of variability in the dependent variable that is explained by the independent variable(s) in a regression model. Conceptually, it quantifies how well the regression model fits the data compared to the mean model (which uses the mean of the dependent variable as the prediction for every observation)

</p>

<p>

Notes: This slide outlines how we allocate the variation in our data between the model and the errors. SST tells us the total variability in our dependent variable, \(y\), while SSR tells us how much of that variability is explained by our regression model. The difference, SSE, is the amount of variability not explained by the model. \(R^2\) gives us the proportion of the total variation that is explained by the model. It's an essential measure of how well our model fits the data.

</p>

</aside>

</section>



<section>

<div class="grid-wrapper">

<div class="header">

<h2>Uncertainty in $\hat{\beta}$ Estimates</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr 1fr;grid-auto-rows:auto;gap:5vmin;">

<!-- MSE Definition -->

<div class="small fragment sided border-info no-hang" data-fragment-index="1" style="grid-column:1/3;">

<p class="small">

We can relate the sampling distributions for the $\beta$ estimates ($\hat{\beta}$

is the estimator for the population $\beta$) by estimating standard error

of the regression from the variance of the residuals (<span class="em">Mean Squared Error</span>):

</p>

<p>$$ MSE = \frac{SSE}{n - p - 1} $$</p>

<p class="smallest">Recall \( SSE \) is the Sum of Squared Errors, $SSE = \sum (y_i - \hat{y})^2$, \( n \) is the number of observations, and \( p \) is the number of predictors (<span class="em">excluding</span> the intercept).</p>

<p class="smallest">

MSE is an estimate of the variance of the error term \( \epsilon \)

in the population model: $Y=\beta_0+\beta_1X+\epsilon$.

</p>

</div>

<!-- SE for Slope (b1) -->

<div class="fragment no-hang" data-fragment-index="2">

<p><span class="em">Standard Error of Slope \( \hat{\beta}_1 \):</span></p>

<div class="smallest">$$ SE(\hat{\beta}_1) = \sqrt{\text{Var}(\hat{\beta}_1)} = \sqrt{\frac{MSE}{\sum (x_i - \bar{x})^2}} $$</div>

<p class="smallest">The standard error of \( \hat{\beta}_1 \) quantifies the precision of the slope estimate. It's calculated as the square root of the variance of \( \hat{\beta}_1 \), which is derived from the mean of the squared deviations of our predictor \( x \) from its mean \( \bar{x} \), scaled by the MSE. This variance reflects how much the slope would vary across different samples from the same population.</p>

</div>

<!-- SE for Intercept (b0) -->

<div class="fragment no-hang" data-fragment-index="3">

<p><span class="em">Standard Error of Intercept \( \hat{\beta}_0 \):</span></p>

<div class="smallest">$$ SE(\hat{\beta}_0) = \sqrt{MSE \left(\frac{1}{n} + \frac{\bar{x}^2}{\sum (x_i - \bar{x})^2}\right)} $$</div>

<p class="smallest">The standard error of \( \hat{\beta}_0 \) represents the spread of the intercept's sampling distribution. The formula accounts for the average squared distance of \( x \) values from their mean, suggesting as this distance increases, or as the sample size \( n \) grows, our estimate of \( \hat{\beta}_0 \) becomes more precise.</p>

</div>

</div>

</div>

</div>

<aside class="notes">

<p>

Just like estimating the se of the mean (recall sqrt(var(x)/(n-1))), we

can estimate the standard error the beta coefficients by assessing the

spread of the residuals wrt to the prediction, and standardizing it.

</p>

<p>

That is, we take the SSE and standardize it by the variation in the x variable, or by scaling it with the average fractional variation in x.

</p>

</aside>

<!-- </section> -->
        </section>
        <section data-background-image="lib/img/inferences_bg.png" id="section-title-2">
          <div class="grid-wrapper">
            <div class="section-title-content" id="section-content-2">
              <div class="section-number">
                <span class="large-number">
                  2
                </span>
              </div>
              <div class="headlines">
                <h2 class="r-fit-text">
                  Making Inferences
                </h2>
                <h3>
                  And Predictions From Linear Models
                </h3>
              </div>
            </div>
          </div>
          <style>

#section-content-2.section-title-content {

background-color: rgba(240, 240, 240, 0.6) !important;

border-radius: 2rem !important;

box-shadow: 0 0 2rem 2rem rgba(240, 240, 240, 0.6) !important;

}

</style>

<aside class="notes">

<p>Section Notes</p>

</aside>

</section> <!-- End section title -->



<!-- Regression Inference intro -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2>Inference</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr;grid-auto-rows:auto;row-gap:1vmin;">

<p>

Previously, our focus was on using regression to describe a dataset

without making <span class="pop">inferences</span> about the population.

Now, we'll explore how to infer population relationships from our

sample, specifically focusing

on <span class="success">estimating the uncertainty</span> of our

model's parameters.

</p>

<p class="em u">

Some questions involving the population that we might ask when analyzing a relationship are:

</p>

<ul>

<li class="fragment">

Does the observed relationship <span class="pop">also occur</span> in the population?

</li>

<li class="fragment">

For a linear relationship, what is the <span class="pop">slope of the regression line</span> in the population?

</li>

<li class="fragment">

What is the <span class="pop">mean value of the response variable</span> (y) for individuals with a specific value of the explanatory variable (x)?

</li>

<li class="fragment">

What <span class="pop">interval of values</span> predicts the value of the response variable (y) for an individual with a specific value of the explanatory variable (x)?

</li>

</ul>

</div>

</div>

</div>

</section>



<!-- Regression to describe population -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2>Describing A Population</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr;grid-auto-rows:auto;gap:2vmin;">

<div>

The regression equation for a simple linear relationship in a population can be written as:

</div>

<div class="danger">

<p>

$$E(Y) = \beta_0 + \beta_1X + \epsilon$$

</p>

</div>

<ul>

<li class="fragment">

$E(Y)$ represents the <span class="info">mean or expected value of y</span> for individuals in the population who all have the same particular value of x. Note that $\hat{y}$ is an estimate of $E(Y)$

</li>

<li class="fragment">

$\beta_0$ is the <span class="info">intercept</span> of the line in the <span class="info">population</span>

</li>

<li class="fragment">

$\beta_1$ is the <span class="info">slope</span> of the regression line in the <span class="info">population</span>. <span class="em"> Note that if the slope $\beta_1 = 0$, there is no linear relationship in the population</span>.

</li>

</ul>

<p class="framed border-danger fragment">

<i class="fas fa-arrow-circle-right danger"></i>

Unless we measure the entire population, we cannot know the numerical values of $\beta_0$ and $\beta_1$. These are population parameters that we <span class="danger">estimate using the corresponding sample statistics</span>.

</p>

</div>

</div>

</div>

</section>

<section data-auto-animate>

<div class="grid-wrapper">

<div class="header">

<h2>High-Precision Positioning</h2>

</div>

<div class="content">

<div class="grid-generic full-width" style="grid-template-columns:2.5fr 1fr;grid-template-rows:1fr;gap:5px;grid-auto-rows:1fr;">

<div style="text-align:justify;text-justify:inter-word;font-size:100%;display:grid;grid-template-columns:1fr;grid-auto-rows:auto;row-gap:2vmin;">

<p>

Inferences from our LVDT device.

</p>

<div style="width:80%;">

<svg width="100%" viewBox="0 0 460.8 345.6">

<use xlink:href="lib/img/regression-example-lvdt.svg#axes_1"></use>

<use style="opacity:0;visibility:hidden;" xlink:href="lib/img/regression-example-lvdt.svg#axes_2"></use>

<use style="opacity:0;visibility:hidden;" xlink:href="lib/img/regression-example-lvdt.svg#axes_3"></use>

</svg>

</div>

</div>

<div class="full-width" style="font-size:90%;text-align:center;">

<table border="1" class="dataframe">

<thead>

<tr style="text-align: center;">

<th>x</th>

<th>y</th>

</tr>

</thead>

<tbody>

<tr>

<td>3.96</td>

<td>4.212</td>

</tr>

<tr>

<td>8.00</td>

<td>7.981</td>

</tr>

<tr>

<td>7.75</td>

<td>6.954</td>

</tr>

<tr>

<td>2.83</td>

<td>2.461</td>

</tr>

<tr>

<td>2.39</td>

<td>2.655</td>

</tr>

<tr>

<td>6.18</td>

<td>6.169</td>

</tr>

<tr>

<td>8.80</td>

<td>8.359</td>

</tr>

<tr>

<td>4.60</td>

<td>4.367</td>

</tr>

<tr>

<td>7.05</td>

<td>7.157</td>

</tr>

<tr>

<td>3.44</td>

<td>3.065</td>

</tr>

</tbody>

</table>

</div>

</div>

</div>

</div>

<aside class="notes">

<p>Now, let's look back at our linear variable differential transformer.</p>

</aside>

</section>



<section data-auto-animate>

<div class="grid-wrapper">

<div class="header">

<h2>High-Precision Positioning</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:3fr 1fr;grid-template-rows:auto;gap:5px;width:80%;">

<div style="font-size:100%;display:grid;grid-template-columns:1fr;grid-auto-rows:auto;row-gap:2vmin;">

<p data-id="instruction">

Recall, the model: $\hat{y}_i=0.10+0.95x_i$ and <br /> "Goodness Of Fit" statistics:

</p>

<div class="grid-generic" style="width:80%;align-self:start;justify-self:center;;grid-template-columns:1fr;grid-template-rows:1fr auto;">

<div style="align-self:start;justify-self:center;">

<div class="no-hang">

$$R^2 = 0.9797\, \&\, \mathrm{RMSE} = 0.3405$$

</div>

</div>

<div data-id="img" style="width:100%;height:100%;align-self:start;justify-self:center;">

<svg height="80%" viewBox="0 0 460.8 345.6">

<use xlink:href="lib/img/regression-example-lvdt.svg#axes_1"></use>

<use xlink:href="lib/img/regression-example-lvdt.svg#axes_2"></use>

<use xlink:href="lib/img/regression-example-lvdt.svg#axes_3"></use>

</svg>

</div>

</div>

</div>

<div class="full-width" style="font-size:80%;text-align:center;">

<table border="1" class="dataframe">

<thead>

<tr class="center-justify">

<th>Displacement (mm)</th>

<th>Voltage (mV)</th>

</tr>

</thead>

<tbody>

<tr>

<td>3.96</td>

<td>4.212</td>

</tr>

<tr>

<td>8.00</td>

<td>7.981</td>

</tr>

<tr>

<td>7.75</td>

<td>6.954</td>

</tr>

<tr>

<td>2.83</td>

<td>2.461</td>

</tr>

<tr>

<td>2.39</td>

<td>2.655</td>

</tr>

<tr>

<td>6.18</td>

<td>6.169</td>

</tr>

<tr>

<td>8.80</td>

<td>8.359</td>

</tr>

<tr>

<td>4.60</td>

<td>4.367</td>

</tr>

<tr>

<td>7.05</td>

<td>7.157</td>

</tr>

<tr>

<td>3.44</td>

<td>3.065</td>

</tr>

</tbody>

</table>

</div>

</div>

</div>

</div>

</section>



<!-- Standard Error Of The Estimates -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2>High-Precision Positioning</h2>

</div>

<div class="content">

<div class="grid-generic no-hang" style="grid-template-columns:2fr 1fr;grid-template-rows:1fr;gap:5px;width:100%;">

<div class="full-width" style="text-align:justify;text-justify:inter-word;font-size:85%;display:grid;grid-template-columns:1fr;grid-auto-rows:auto;row-gap:2vmin;">

<h3 style="justify-self:center;text-align:center;">

Residuals Analysis

</h3>

<ul>

<li >Residual: The difference between actual and predicted values ($y_i-\hat{y}_i$).</li>

<li >If appropriate model chosen, residuals should have no apparent pattern, i.e., they should <span class="em">appear random</span>.</li>

<li class="emoji-exclamation" >Do we have an obvious pattern or relationship?</li>

<li class="emoji-question" >Homoscedastic   <span class="success" ><i class="fa-solid fa-check"></i></span></li>

<li class="emoji-star" >There is no apparent pattern in the distribution of residuals w.r.t displacement.</li>

<li class="emoji-question" >Gaussian (Normal) Distributed   <span class="success" ><i class="fa-solid fa-check"></i></span></li>

<li class="emoji-star" >There is apparently random distribution of residuals around $0$, with relatively more frequent residuals near $0$.</li>

<li class="emoji-question" >Independent   <span class="success" ><i class="fa-solid fa-check"></i></span></li>

<li class="emoji-star" >There is no apparent dependence of $y_{i+1}$ on $x_i$.</li>

</ul>

<p class="framed border-success"  style="text-align:center;">

It appears our <span class="success">Linear Model</span> is appropriate!

</p>

</div>

<div class="full-width" style="justify-self:start;">

<svg width="100%" viewBox="0 0 288 432">

<use xlink:href="lib/img/regression-example-lvdt-residuals.svg#axes_1"></use>

<use xlink:href="lib/img/regression-example-lvdt-residuals.svg#axes_2"></use>

<use xlink:href="lib/img/regression-example-lvdt-residuals.svg#axes_3"></use>

</svg>

</div>

</div>

</div>

</div>

<aside class="notes">

<ul style="font-size:80%">

<li>We can use a number of methods to evaluate if our model is well fit. It is always advisable to look at the residuals.</li>

<li>We can test residuals for a few features before we can really trust our coefficient of determination and RMSE</li>

<li>Is there any qualitative pattern? How about a pattern we can quantify?</li>

<li>If it were heteroscedastic, what could we do?</li>

<li>What are ways we can test for normality? Histogram, Q-Norm, Shapiro-Wilks...</li>

<li>Independence meaning, it shouldn't matter what order I collected the data in.</li>

</ul>

</aside>

</section>



<!-- Null Hypothesis For the Slope -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2>Inference About the Slope</h2>

</div>

<div class="content">

<div class="grid-generic no-hang" style="grid-template-columns:2fr 1fr;grid-template-rows:1fr;gap:5px;width:100%;">

<div class="full-width small no-hang" style="display:grid;grid-template-columns:1fr;grid-auto-rows:auto;row-gap:2vmin;">

<p class="small">

To quantify our uncertainty we need:

</p>

<p class="smaller">

$\text{MSE}=\frac{SSE}{n-p-1}=\frac{0.928}{10-1-1}=0.116$, and $SE(\hat{\beta}_1)=\sqrt{\frac{0.116}{49.29}}=0.0485$

</p>

<p class="smaller">Then, 95% CI:

$\hat{\beta}_1 \pm t_{\alpha/2,\nu}\times SE(\hat{\beta}_1)=\hat{\beta}_1\pm 0.961\times 0.0485=\class{success}{0.952\pm 0.047}$.

</p>

<p class="fragment" data-fragment-index="1">

With $\hat{\beta}_1$, we can state our <span class="danger">null</span> and <span class="success">alternate</span> hypotheses:

$$

\begin{align}

\class{danger}{H_0}:\, \hat{\beta}_1 &=0,\mathrm{\, there\, is\, no\, change\, in\, Y|X\, (no\, relationship)},\\

\class{success}{H_a}:\, \hat{\beta}_1 &\neq 0,\mathrm{\, there\, is\, a\, change\, in\, Y|X\, (a\, relationship)}.

\end{align}

$$

</p>

<p class="fragment" data-fragment-index="2">

Like other $t$-statistics, this one is: $t=\frac{\hat{\beta}_1-\beta_{1}}{SE(\hat{\beta}_1)}$.

</p>

<p class="fragment small" data-fragment-index="3">

$t=\frac{0.952-\class{danger}{H_0}}{0.0485}=19.629$

</p>

<p class="fragment small" data-fragment-index="3">

We find the <span class="info">two-tailed</span> critical value,

$T_{1-0.05/2,\nu=8}=2.306 \ll 19.629$. So, we reject the null

hypothesis and state that

we have a <span class="success">statistically significant linear

relationship</span> between <span class="em">Displacement</span>

and <span class="em">Output Voltage</span>.

</p>

<p class="fragment" data-fragment-index="4" style="font-size:90%;">

<i class="fa-solid fa-circle-exclamation warning"></i> Does the 95% confidence interval exclude $0\frac{mV}{mm}$? Is $T_{\frac{\alpha}{2},\nu}\ll t$?

</p>

</div>

<div class="full-width" style="justify-self:start;">

<svg width="100%" viewBox="0 0 288 432">

<use xlink:href="lib/img/regression-example-lvdt-residuals.svg#axes_1"></use>

<use xlink:href="lib/img/regression-example-lvdt-residuals.svg#axes_2"></use>

<use xlink:href="lib/img/regression-example-lvdt-residuals.svg#axes_3"></use>

</svg>

</div>

</div>

</div>

</div>

<aside class="notes">

<p>

Of course we could do the same with the intercept parameter, you should try it on your own.

</p>

</aside>

<!-- </section> -->
        </section>
        <section data-background-image="lib/img/multigroup_5.png" id="section-title-3">
          <div class="grid-wrapper">
            <div class="section-title-content" id="section-content-3">
              <div class="section-number">
                <span class="large-number">
                  3
                </span>
              </div>
              <div class="headlines">
                <h2 class="r-fit-text">
                  Multiple Linear Regression
                </h2>
                <h3>
                  More Than 1 Explanatory Variables
                </h3>
              </div>
            </div>
          </div>
          <style>

#section-content-3.section-title-content {

background-color: rgba(240, 240, 240, 0.6) !important;

border-radius: 2rem !important;

box-shadow: 0 0 2rem 2rem rgba(240, 240, 240, 0.6) !important;

}

</style>

<aside class="notes">

<p>Section Notes</p>

</aside>

</section> <!-- End section title -->

<!-- Multiple Linear Regression Introduction -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2>Multiple Linear Regression</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr;grid-auto-rows:auto;gap:1vmin;">

<p class="small sided border-info">Multiple linear regression extends simple linear regression by including multiple predictor variables to explain the response variable.</p>

<div class="left-justify">

<p class="fragment" data-fragment-index="1">The general form is:</p>

<p class="fragment math" data-fragment-index="2">$Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + ... + \beta_kX_k + \epsilon$</p>

<ul class="fragment small" data-fragment-index="3">

<li><strong>$Y$</strong>: Response variable</li>

<li><strong>$X_1, X_2, ..., X_k$</strong>: Predictor variables</li>

<li><strong>$\beta_0$</strong>: Y-intercept</li>

<li><strong>$\beta_1, \beta_2, ..., \beta_k$</strong>: Regression coefficients</li>

<li><strong>$\epsilon$</strong>: Random error term</li>

</ul>

</div>

</div>

</div>

</div>

</section>



<!-- Key Assumptions -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2>Key Assumptions</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr;grid-auto-rows:auto;gap:1vmin;">

<div class="left-justify">

<ol>

<li class="fragment emoji-microscope" data-fragment-index="1"><strong>Linearity:</strong> The relationship between predictors and response is linear</li>

<li class="fragment emoji-chart" data-fragment-index="2"><strong>Independence:</strong> Observations are independent of each other</li>

<li class="fragment emoji-graph" data-fragment-index="3"><strong>Homoscedasticity:</strong> Constant variance of residuals</li>

<li class="fragment emoji-brain" data-fragment-index="4"><strong>Normality:</strong> Residuals follow normal distribution</li>

<li class="fragment emoji-warning_icon" data-fragment-index="5"><strong>No Multicollinearity:</strong> Predictors are not highly correlated</li>

</ol>

</div>

</div>

</div>

</div>

</section>



<!-- Interpretation -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2>Interpreting Coefficients</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr 1fr;grid-auto-rows:auto;gap:1vmin;">

<div>

<p class="fragment" data-fragment-index="1"><i class="bulb"></i> Each coefficient represents:</p>

<p class="fragment small sided-bg-info" data-fragment-index="2">The expected change in $Y$ for a one-unit increase in $X_i$, holding all other predictors constant</p>

</div>

<div class="fragment" data-fragment-index="3">

<p><i class="warning"></i> Important Considerations:</p>

<ul class="small">

<li>Units matter</li>

<li>Coefficients are partial effects</li>

<li>Interpretation depends on model scale</li>

</ul>

</div>

</div>

</div>

</div>

</section>



<!-- Colinearity -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2>Colinearity</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr 1fr;grid-auto-rows:auto;gap:1vmin;">

<p style="grid-column: 1/3;" class="small sided border-info">Colinearity is when two or more predictor variables are highly correlated with each other.</p>

<div style="height: 100%">

<p>Multiple regression with no collinearity: <br><span class="fragment success" data-fragment-index="1">Fit the surface</span></p>

<div class="r-stack" style="height: 60vh;">

<img src="lib/img/multiple-regression-3d.png" alt="Static Image" class="graphic full-width static-img">

<img src="lib/img/multiple-regression-3d.gif" alt="Animated Image" class="graphic full-width fragment gif-img current-visble" data-fragment-index="1">

</div>

</div>

<div style="height: 100%">

<p>Multiple regression with collinearity: <span class="fragment success" data-fragment-index="2">Infinite number of solutions</span></p>

<div class="r-stack" style="height: 60vh;">

<img src="lib/img/multiple-regression-3d-collinear.png" alt="Static Image" class="graphic full-width static-img">

<img src="lib/img/multiple-regression-3d-collinear.gif" alt="Animated Image" class="graphic full-width fragment gif-img current-visble" data-fragment-index="2">

</div>

</div>

</div>

</div>

</div>

</section>



<!-- Potential Solutions -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2>Potential Solutions</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr;grid-auto-rows:auto;gap:1vmin;">

<div class="left-justify smaller">

<ol>

<li class="fragment" data-fragment-index="1"><strong>Variance Inflation Factor (VIF):</strong>

<ul>

<li><strong>Calculate VIF:</strong> Assess the degree of multicollinearity by computing the VIF for each predictor. A VIF value exceeding 5 or 10 indicates significant multicollinearity.</li>

<li><strong>Iterative Removal:</strong> Remove predictors with the highest VIF values one at a time, recalculating VIFs after each removal, until all VIFs are below the chosen threshold.</li>

</ul>

</li>

<li class="fragment" data-fragment-index="2"><strong>Stepwise Regression:</strong>

<ul>

<li><strong>Procedure:</strong> Automatically add or remove predictors based on specific criteria (e.g., p-values) to identify a subset of variables that contribute significantly to the model.</li>

<li><strong>Caution:</strong> Stepwise regression can sometimes remove important variables whose significance is affected by multicollinearity. It's essential to assess multicollinearity before applying stepwise methods.</li>

</ul>

</li>

<li class="fragment" data-fragment-index="3"><strong>Alternative Methods:</strong>

<ul>

<li><strong>Principal Component Analysis (PCA):</strong> Transform correlated predictors into a set of uncorrelated components.</li>

<li><strong>Regularization Techniques:</strong> Apply methods like Ridge Regression or LASSO, which can handle multicollinearity by adding a penalty to the regression coefficients.</li>

</ul>

</li>

</ol>

</div>

</div>

</div>

</div>

</section>



<!-- VIF -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2>VIF</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr;grid-auto-rows:auto;gap:1vmin;">

<div class="left-justify">

<p class="fragment" data-fragment-index="1">VIF measures how much the variance of a regression coefficient increases due to multicollinearity</p>

<div class="fragment" data-fragment-index="2">

<p class="math">VIF<sub>j</sub> = 1/(1-R<sub>j</sub><sup>2</sup>)</p>

<p class="small">where R<sub>j</sub><sup>2</sup> is from regressing predictor j on all other predictors</p>

</div>

<ul class="fragment small" data-fragment-index="3">

<li>VIF = 1: No correlation with other predictors</li>

<li>VIF > 5: Moderate multicollinearity</li>

<li>VIF > 10: Severe multicollinearity</li>

</ul>

</div>

</div>

</div>

</div>

<!-- </section> -->
        </section>
        <section data-background-gradient="radial-gradient(#ffffff, #808080)" id="section-title-4">
          <div class="grid-wrapper">
            <div class="section-title-content" id="section-content-4">
              <div class="section-number">
                <span class="large-number">
                  4
                </span>
              </div>
              <div class="headlines">
                <h2 class="r-fit-text">
                  Quiz 5
                </h2>
                <h3>
                  Passcode: Pearson
                </h3>
              </div>
            </div>
          </div>
          <aside class="notes">

<p>Quiz 5 on Bivariate Relationships</p>

</aside>

</section> <!-- End section title -->
        </section>
      </div>
      <footer class="main-footer">
        <span>
          Lecture 15
        </span>
        <span style="text-align:center;">
        </span>
        <span style="text-align:right;">
          <a href="https:\\khrisgriffis.com" target="_blank" rel="noopener noreferrer">Khris Griffis &#169;2025</a>
        </span>
      </footer>
    </div>
    <script src="./src/reveal.js">
    </script>
    <script src="./src/plugin/notes/notes.js">
    </script>
    <script src="./src/plugin/highlight/highlight.js">
    </script>
    <script src="./src/plugin/math/math.js">
    </script>
    <script src="./src/plugin/reveal-splash/reveal-splash.js">
    </script>
    <script src="./src/plugin/vizzy-reveal/vizzy.js">
    </script>
    <script>
      Reveal.initialize({
autoSlide: 0,
center: true,
controls: true,
controlsBackArrows: "faded",
controlsLayout: "bottom-right",
display: "block",
fragments: true,
fragmentInURL: true,
hash: true,
hideCursorTime: 5000,
keyboard: true,
mobileViewDistance: 3,
mouseWheel: false,
navigationMode: "linear",
overview: true,
pdfMaxPagesPerSlide: 1,
pdfSeparateFragments: false,
preloadIframes: null,
progress: false,
showNotes: false,
showSlideNumber: "print",
sortFragmentsOnSync: true,
touch: true,
transition: "fade",
transitionSpeed: "default",
viewDistance: 3,
backgroundTransition: "fade",
controlsTutorial: false,
embedded: false,
help: true,
hideInactiveCursor: true,
history: false,
loop: false,
previewLinks: false,
rtl: false,
shuffle: false,
slideNumber: false,
width: 1920,
height: 1080,
margin: 0.081,
minScale: 0.08,
maxScale: 1.67,
mathjax3: {
mathjax: "https://cdn.jsdelivr.net/npm/mathjax@4.0.0-beta.7/tex-mml-chtml.js",
loader: {
load: [
"[tex]/html",
],
},
tex: {
packages: {
'[+]': [
"html",
],
},
inlineMath: [
["$", "$"],
["\\(", "\\)"],
],
processEscapes: true,
processEnvironments: true,
},
options: {
skipHtmlTags: [
"script",
"noscript",
"style",
"textarea",
"pre",
],
enableMenu: false,
},
chtml: {
scale: 0.8,
minScale: 0.4,
},
Safe: {
sizeMin: 0.4,
sizeMax: 1.25,
},
output: {
linebreaks: {
inline: true,
width: "100%",
lineleading: 0.2,
LinebreakVisitor: null,
},
},
},
notes: {

},
highlight: {

},
vizzy: {
autoRunTransitions: true,
autoTransitionDelay: 100,
devMode: false,
onSlideChangedDelay: 0,
},
splash: {
splashImage: "lib/img/ME3040_splash.png",
text: "Welcome to ME3040!",
minimumDisplay: 2,
},
plugins: [RevealNotes, RevealHighlight, RevealMath.MathJax3, Splash, Vizzy]
});
    </script>
  </body>
</html>
